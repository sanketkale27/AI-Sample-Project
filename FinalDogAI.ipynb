{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = \"C:/Users/sanky/OneDrive/Documents/aima-python-master/PetImages\"\n",
    "\n",
    "CATEGORIES = [\"Dog\", \"Cat\"]\n",
    "\n",
    "for category in CATEGORIES:  # do dogs and cats\n",
    "    path = os.path.join(DATADIR,category)  # create path to dogs and cats\n",
    "    for img in os.listdir(path):  # iterate over each image per dogs and cats\n",
    "        img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "       \n",
    "\n",
    "        break  # we just want one for now so break\n",
    "    break  #...and one more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[117 117 119 ... 133 132 132]\n",
      " [118 117 119 ... 135 134 134]\n",
      " [119 118 120 ... 137 136 136]\n",
      " ...\n",
      " [ 79  74  73 ...  80  76  73]\n",
      " [ 78  72  69 ...  72  73  74]\n",
      " [ 74  71  70 ...  75  73  71]]\n"
     ]
    }
   ],
   "source": [
    "print(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(375, 500)\n"
     ]
    }
   ],
   "source": [
    "print(img_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 80\n",
    "\n",
    "new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24946\n"
     ]
    }
   ],
   "source": [
    "training_data = []\n",
    "\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:  # do dogs and cats\n",
    "\n",
    "        path = os.path.join(DATADIR,category)  # create path to dogs and cats\n",
    "        class_num = CATEGORIES.index(category)  # get the classification  (0 or a 1). 0=dog 1=cat\n",
    "\n",
    "        for img in os.listdir(path):  # iterate over each image per dogs and cats\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
    "                training_data.append([new_array, class_num])  # add this to our training_data\n",
    "            except Exception as e:  # in the interest in keeping the output clean...\n",
    "                pass\n",
    "            #except OSError as e:\n",
    "            #    print(\"OSErrroBad img most likely\", e, os.path.join(path,img))\n",
    "            #except Exception as e:\n",
    "            #    print(\"general exception\", e, os.path.join(path,img))\n",
    "\n",
    "create_training_data()\n",
    "\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(training_data)\n",
    "for sample in training_data[:10]:\n",
    "    print(sample[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 31]\n",
      "   [ 21]\n",
      "   [ 20]\n",
      "   ...\n",
      "   [167]\n",
      "   [ 57]\n",
      "   [ 79]]\n",
      "\n",
      "  [[  7]\n",
      "   [ 17]\n",
      "   [ 19]\n",
      "   ...\n",
      "   [ 53]\n",
      "   [ 56]\n",
      "   [ 72]]\n",
      "\n",
      "  [[  6]\n",
      "   [ 17]\n",
      "   [112]\n",
      "   ...\n",
      "   [ 53]\n",
      "   [ 53]\n",
      "   [ 69]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[  8]\n",
      "   [ 17]\n",
      "   [ 24]\n",
      "   ...\n",
      "   [134]\n",
      "   [123]\n",
      "   [139]]\n",
      "\n",
      "  [[  6]\n",
      "   [ 21]\n",
      "   [ 21]\n",
      "   ...\n",
      "   [ 91]\n",
      "   [100]\n",
      "   [135]]\n",
      "\n",
      "  [[  4]\n",
      "   [ 15]\n",
      "   [ 14]\n",
      "   ...\n",
      "   [ 68]\n",
      "   [127]\n",
      "   [128]]]]\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for features,label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "\n",
    "print(X[0].reshape(-1, IMG_SIZE, IMG_SIZE, 1))\n",
    "\n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_out = open(\"X.pickle\",\"wb\")\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y.pickle\",\"wb\")\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "546/546 [==============================] - 531s 973ms/step - loss: 0.6758 - accuracy: 0.6019 - val_loss: 0.6337 - val_accuracy: 0.6379\n",
      "Epoch 2/10\n",
      "546/546 [==============================] - 520s 953ms/step - loss: 0.6005 - accuracy: 0.6822 - val_loss: 0.5943 - val_accuracy: 0.6860\n",
      "Epoch 3/10\n",
      "546/546 [==============================] - 517s 947ms/step - loss: 0.5432 - accuracy: 0.7291 - val_loss: 0.5604 - val_accuracy: 0.7129\n",
      "Epoch 4/10\n",
      "546/546 [==============================] - 520s 953ms/step - loss: 0.5054 - accuracy: 0.7568 - val_loss: 0.5423 - val_accuracy: 0.7281\n",
      "Epoch 5/10\n",
      "546/546 [==============================] - 523s 957ms/step - loss: 0.4684 - accuracy: 0.7823 - val_loss: 0.5099 - val_accuracy: 0.7594\n",
      "Epoch 6/10\n",
      "546/546 [==============================] - 516s 945ms/step - loss: 0.4389 - accuracy: 0.7995 - val_loss: 0.5140 - val_accuracy: 0.7596\n",
      "Epoch 7/10\n",
      "546/546 [==============================] - 506s 927ms/step - loss: 0.4159 - accuracy: 0.8068 - val_loss: 0.5036 - val_accuracy: 0.7652\n",
      "Epoch 8/10\n",
      "546/546 [==============================] - 487s 893ms/step - loss: 0.3926 - accuracy: 0.8246 - val_loss: 0.5438 - val_accuracy: 0.7475\n",
      "Epoch 9/10\n",
      "546/546 [==============================] - 511s 937ms/step - loss: 0.3689 - accuracy: 0.8348 - val_loss: 0.5255 - val_accuracy: 0.7654\n",
      "Epoch 10/10\n",
      "546/546 [==============================] - 511s 937ms/step - loss: 0.3492 - accuracy: 0.8477 - val_loss: 0.5236 - val_accuracy: 0.7704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13a423871c0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "\n",
    "pickle_in = open(\"X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)\n",
    "\n",
    "\n",
    "X=np.array(X/255.0)\n",
    "y=np.array(y)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), input_shape=X.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "\n",
    "model.add(Dense(64))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, y, batch_size=32, epochs=10,validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array = cv2.imread(\"C:/Users/sanky/OneDrive/Documents/aima-python-master/PetImages/Cat/4.jpg\" ,cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(new_array).reshape(-1, IMG_SIZE, IMG_SIZE, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=np.array(X_test/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7904881]], dtype=float32)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
